{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-Attention Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Data Check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NSMC 데이터\n",
    "    - Naver sentiment movie corpus v1.0\n",
    "    - 네이버 영화 댓글 감정분석 데이터셋\n",
    "    - 이진 분류\n",
    "- https://github.com/e9t/nsmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                           document  label\n",
       "0  9976970                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1  3819312  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/ratings_train.txt', sep='\\t')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    75173\n",
       "1    74827\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    5\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149995, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(how='any', axis=0)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for doc in df['document']:\n",
    "    for token in doc.split():\n",
    "        vocab.add(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "357862"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_cnt_dict = {}\n",
    "for doc in df['document']:\n",
    "    for token in doc.split():\n",
    "        if token not in vocab_cnt_dict:\n",
    "            vocab_cnt_dict[token] = 0\n",
    "        vocab_cnt_dict[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_cnt_list = [(token, cnt) for token, cnt in vocab_cnt_dict.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_vocabs = sorted(vocab_cnt_list, key= lambda tup: tup[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts = [cnt for _, cnt in top_vocabs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_vocab = sum(np.array(cnts)>=3)\n",
    "top_vocabs = top_vocabs[:n_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['영화', '너무', '정말', '진짜', '이']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs = [token for token, _ in top_vocabs]\n",
    "vocabs[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## UNK, PAD Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs.insert(0, '[UNK]')\n",
    "vocabs.insert(0, '[PAD]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_token = vocabs\n",
    "token_to_idx = {token: i for i, token in enumerate(idx_to_token)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self, vocabs, use_padding=True, max_padding=64, pad_token='[PAD]', unk_token='[UNK]'):\n",
    "        self.idx_to_token = vocabs\n",
    "        self.token_to_idx = {token: i for i, token in enumerate(self.idx_to_token)}\n",
    "        \n",
    "        self.use_padding = use_padding\n",
    "        self.max_padding = max_padding\n",
    "        \n",
    "        self.pad_token = pad_token\n",
    "        self.unk_token = unk_token\n",
    "        \n",
    "        self.unk_token_idx = self.token_to_idx[self.unk_token]\n",
    "        self.pad_token_idx = self.token_to_idx[self.pad_token]\n",
    "        \n",
    "    def __call__(self, x:str):\n",
    "        token_ids = []\n",
    "        token_list = x.split()\n",
    "        \n",
    "        for token in token_list:\n",
    "            if token in self.token_to_idx:\n",
    "                token_idx = self.token_to_idx[token]\n",
    "            else:\n",
    "                token_idx = self.unk_token_idx\n",
    "            token_ids.append(token_idx)\n",
    "        \n",
    "        if self.use_padding:\n",
    "            token_ids = token_ids[:self.max_padding]\n",
    "            n_pads = self.max_padding - len(token_ids)\n",
    "            token_ids = token_ids + [self.pad_token_idx] * n_pads\n",
    "        \n",
    "        return token_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(vocabs, use_padding=True, max_padding=50, pad_token='[PAD]', unk_token='[UNK]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
